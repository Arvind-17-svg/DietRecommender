{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pymupdf4llm as pfllm\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "\n",
    "def extract_markdown_from_pdf(pdf_path: str) -> str:\n",
    "    return pfllm.to_markdown(pdf_path)\n",
    "\n",
    "\n",
    "def chunk_markdown(md_text: str, source_name=\"sr28_doc.pdf\") -> List[Document]:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=300,\n",
    "        chunk_overlap=50,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    "    )\n",
    "\n",
    "    chunks = splitter.create_documents([md_text])\n",
    "\n",
    "    # Attach metadata\n",
    "    for chunk in chunks:\n",
    "        chunk.metadata[\"source\"] = source_name\n",
    "        chunk.metadata[\"type\"] = \"usda\"\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def embed_chunks(chunks: List[Document]):\n",
    "    model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    texts = [chunk.page_content for chunk in chunks]\n",
    "    return model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_to_pinecone(chunks: List[Document], embeddings, index_name=\"nutrition-index\"):\n",
    "    load_dotenv(dotenv_path=\"FoodNutritionAssistant/.env\")\n",
    "    pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "    pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "    if index_name not in pc.list_indexes().names():\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=384,\n",
    "            metric=\"cosine\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "        )\n",
    "\n",
    "    index = pc.Index(index_name)\n",
    "\n",
    "    vectors = []\n",
    "    for chunk, embedding in tqdm(zip(chunks, embeddings), total=len(chunks)):\n",
    "        vectors.append({\n",
    "            \"id\": str(uuid.uuid4()),\n",
    "            \"values\": embedding.tolist(),\n",
    "            \"metadata\": chunk.metadata\n",
    "        })\n",
    "\n",
    "    # Batch upsert\n",
    "    batch_size = 100\n",
    "    for i in range(0, len(vectors), batch_size):\n",
    "        batch = vectors[i:i+batch_size]\n",
    "        res = index.upsert(vectors=batch)\n",
    "        print(f\"Upserted batch {i // batch_size + 1}: {res}\")\n",
    "\n",
    "    print(\"Index stats:\", index.describe_index_stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1817/1817 [00:00<00:00, 52649.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted batch 1: {'upserted_count': 100}\n",
      "Upserted batch 2: {'upserted_count': 100}\n",
      "Upserted batch 3: {'upserted_count': 100}\n",
      "Upserted batch 4: {'upserted_count': 100}\n",
      "Upserted batch 5: {'upserted_count': 100}\n",
      "Upserted batch 6: {'upserted_count': 100}\n",
      "Upserted batch 7: {'upserted_count': 100}\n",
      "Upserted batch 8: {'upserted_count': 100}\n",
      "Upserted batch 9: {'upserted_count': 100}\n",
      "Upserted batch 10: {'upserted_count': 100}\n",
      "Upserted batch 11: {'upserted_count': 100}\n",
      "Upserted batch 12: {'upserted_count': 100}\n",
      "Upserted batch 13: {'upserted_count': 100}\n",
      "Upserted batch 14: {'upserted_count': 100}\n",
      "Upserted batch 15: {'upserted_count': 100}\n",
      "Upserted batch 16: {'upserted_count': 100}\n",
      "Upserted batch 17: {'upserted_count': 100}\n",
      "Upserted batch 18: {'upserted_count': 100}\n",
      "Upserted batch 19: {'upserted_count': 17}\n",
      "Index stats: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 3506}},\n",
      " 'total_vector_count': 3506}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"/Users/arvindranganathraghuraman/Desktop/Personal_Projects/Nutrition_Dataset/sr28_doc.pdf\"\n",
    "\n",
    "    md_text = extract_markdown_from_pdf(pdf_path)\n",
    "    chunks = chunk_markdown(md_text)\n",
    "    embeddings = embed_chunks(chunks)\n",
    "    upsert_to_pinecone(chunks, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n",
      "Found document with no `text` key. Skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA Response: A medium-sized banana typically contains:\n",
      "\n",
      "* Calories: 105\n",
      "* Carbohydrates: 26.9 grams (mainly starch and sugars)\n",
      "* Fiber: 3.1 grams\n",
      "* Protein: 1.3 grams\n",
      "* Fat: 0.5 grams\n",
      "* Potassium: 422 milligrams (about 12% of the Daily Value (DV))\n",
      "* Vitamin C: 10.3 milligrams (about 17% of the DV)\n",
      "* Vitamin B6: 0.5 milligrams (about 25% of the DV)\n",
      "\n",
      "Please note that these values can vary depending on the ripeness, variety, and growing conditions of the banana.\n",
      "\n",
      "Would you like to know more about a specific aspect of banana nutrition?\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "from langchain_pinecone import Pinecone as PineconeVectorStore\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# 1. LLM\n",
    "llm = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "# 2. Embedding model (correct wrapper)\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# 3. Pinecone vector store\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=\"nutrition-index\",\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# 4. Retriever + RAG pipeline\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\")\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# 5. Ask your question\n",
    "prompt = \"What is the nutritional value of a banana?\"\n",
    "result = qa({\"query\": prompt})\n",
    "print(\"QA Response:\", result[\"result\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
